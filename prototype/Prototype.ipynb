{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "import json\n",
    "import urllib.parse\n",
    "\n",
    "import boto3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslatedText:\n",
    "    \n",
    "    def __init__(self, original, original_lang, translated, translated_lang):\n",
    "        self._original = original\n",
    "        self._original_lang = original_lang\n",
    "        self._translated = translated\n",
    "        self._translated_lang = translated_lang\n",
    "    \n",
    "    def get_original(self):\n",
    "        return self._original\n",
    "    \n",
    "    def get_original_lang(self):\n",
    "        return self._original_lang\n",
    "    \n",
    "    def get_translated(self):\n",
    "        return self._translated\n",
    "    \n",
    "    def get_translated_lang(self):\n",
    "        return self._translated_lang\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'original': {\n",
    "                'language': self.get_original_lang(),\n",
    "                'body': self.get_original()\n",
    "            },\n",
    "            'translated': {\n",
    "                'language': self.get_translated_lang(),\n",
    "                'body': self.get_translated()\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Locale:\n",
    "    \n",
    "    def __init__(self, country, language):\n",
    "        self._country = country\n",
    "        self._language = language\n",
    "    \n",
    "    def get_country(self):\n",
    "        return self._country\n",
    "    \n",
    "    def get_language(self):\n",
    "        return self._language\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'country': self.get_country(),\n",
    "            'language': self.get_language()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Source:\n",
    "    \n",
    "    def __init__(self, name, url, categories, language, country):\n",
    "        self._name = name\n",
    "        self._url = url\n",
    "        self._categories = categories\n",
    "        self._language = language\n",
    "        self._country = country\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self._name\n",
    "    \n",
    "    def get_url(self):\n",
    "        return self._url\n",
    "    \n",
    "    def get_categories(self):\n",
    "        return self._categories\n",
    "    \n",
    "    def get_language(self):\n",
    "        return self._language\n",
    "    \n",
    "    def get_country(self):\n",
    "        return self._country\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'name': self.get_name(),\n",
    "            'url': self.get_url(),\n",
    "            'categories': self.get_categories(),\n",
    "            'language': self.get_language(),\n",
    "            'country': self.get_country()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    \n",
    "    def __init__(self, url, title, keywords, creator, content, publish_datetime,\n",
    "        category, locale):\n",
    "        self._url = url\n",
    "        self._title = title\n",
    "        self._keywords = keywords\n",
    "        self._creator = creator\n",
    "        self._content = content\n",
    "        self._publish_datetime = publish_datetime\n",
    "        self._category = category\n",
    "        self._locale = locale\n",
    "    \n",
    "    def get_url(self):\n",
    "        return self._url\n",
    "    \n",
    "    def get_title(self):\n",
    "        return self._title\n",
    "    \n",
    "    def get_keywords(self):\n",
    "        return self._keywords\n",
    "    \n",
    "    def get_creator(self):\n",
    "        return self._creator\n",
    "    \n",
    "    def get_content(self):\n",
    "        return self._content\n",
    "    \n",
    "    def get_publish_datetime(self):\n",
    "        return self._publish_datetime\n",
    "    \n",
    "    def get_category(self):\n",
    "        return self._category\n",
    "    \n",
    "    def get_locale(self):\n",
    "        return self._locale\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'url': self.get_url(),\n",
    "            'title': self.get_title().to_dict(),\n",
    "            'content': self.get_content().to_dict(),\n",
    "            'keywords': self.get_keywords(),\n",
    "            'creator': self.get_creator(),\n",
    "            'published': self.get_publish_datetime(),\n",
    "            'category': self.get_category(),\n",
    "            'locale': self.get_locale().to_dict()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('docs_languages.csv') as f:\n",
    "    records = csv.DictReader(f)\n",
    "    records_sanitized = map(\n",
    "        lambda x: (x['Language'].lower().strip(), x['Language Code'].lower().strip()),\n",
    "        records\n",
    "    )\n",
    "    indexed_languages = dict(records_sanitized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_language_code(full_name):\n",
    "    full_name_safe = full_name.lower().strip()\n",
    "    return indexed_languages[full_name_safe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslateChunker:\n",
    "    \n",
    "    def __init__(self, max_size=950):\n",
    "        self._current_word = ''\n",
    "        self._current_chunk = ''\n",
    "        self._chunks = []\n",
    "        self._max_size = max_size\n",
    "        self._finished = False\n",
    "    \n",
    "    def process(self, char):\n",
    "        assert not self._finished\n",
    "        \n",
    "        if char == ' ':\n",
    "            self._accept_current_word()\n",
    "        else:\n",
    "            self._current_word += char\n",
    "    \n",
    "    def finish(self):\n",
    "        assert not self._finished\n",
    "        self._accept_current_word()\n",
    "        self._accept_current_chunk()\n",
    "        self._finished = True\n",
    "    \n",
    "    def get_chunks(self):\n",
    "        assert self._finished\n",
    "        \n",
    "        def is_ok_size(target):\n",
    "            length = len(target)\n",
    "            return length > 0 and length < self._max_size\n",
    "        \n",
    "        return filter(is_ok_size, self._chunks)\n",
    "    \n",
    "    def _accept_current_chunk(self):\n",
    "        self._chunks.append(self._current_chunk.strip())\n",
    "        self._current_chunk = ''\n",
    "    \n",
    "    def _accept_current_word(self):\n",
    "        if len(self._current_word) > self._max_size:\n",
    "            self._current_word = self._current_word[:self._max_size]\n",
    "        \n",
    "        possible_size = len(self._current_chunk) + len(self._current_word) + 1\n",
    "        if possible_size > self._max_size:\n",
    "            self._accept_current_chunk()\n",
    "        \n",
    "        self._current_chunk = self._current_chunk + ' ' + self._current_word\n",
    "        self._current_word = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryFacade:\n",
    "    \n",
    "    def __init__(self, news_data_key, aws_key, news_data_endpoint=None, aws_region=None):\n",
    "        self._translate_cache = {}\n",
    "        \n",
    "        self._news_data_key = news_data_key\n",
    "        self._aws_key = aws_key\n",
    "        \n",
    "        if news_data_endpoint is None:\n",
    "            news_data_endpoint = 'https://newsdata.io/api/1/'\n",
    "        \n",
    "        self._news_data_endpoint = news_data_endpoint\n",
    "        \n",
    "        if aws_region is None:\n",
    "            aws_region = 'us-east-2'\n",
    "        \n",
    "        self._aws_region = aws_region\n",
    "        \n",
    "        self._translate_client = self._build_translate_client()\n",
    "    \n",
    "    def sample_sources(self, country):\n",
    "        def parse_record(record):\n",
    "            name = record['source_id']\n",
    "            url = urllib.parse.urlparse(record['link']).netloc\n",
    "            categories = record['category']\n",
    "            language = lookup_language_code(record['language'])\n",
    "            return Source(name, url, categories, language, country)\n",
    "        \n",
    "        def get_for_priority(priority, top=True):\n",
    "            params = {\n",
    "                'prioritydomain': priority,\n",
    "                'country': country,\n",
    "                'apikey': newsdata_key\n",
    "            }\n",
    "            \n",
    "            if top:\n",
    "                params['category'] = 'top'\n",
    "            \n",
    "            response = requests.get(\n",
    "                self._news_data_endpoint + 'news',\n",
    "                params=params\n",
    "            )\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                raise RuntimeError('Error (%d): %s' % (response.status_code, response.text))\n",
    "\n",
    "            raw_results = response.json()['results']\n",
    "            parsed_results = map(lambda record: parse_record(record), raw_results)\n",
    "            \n",
    "            output_names = set()\n",
    "            output_records = []\n",
    "            for result in parsed_results:\n",
    "                if result.get_name() not in output_names:\n",
    "                    output_names.add(result.get_name())\n",
    "                    output_records.append(result)\n",
    "            \n",
    "            return output_records\n",
    "        \n",
    "        sources = get_for_priority('top', top=True)\n",
    "        \n",
    "        if len(sources) < 5:\n",
    "            sources += get_for_priority('medium', top=True)\n",
    "        \n",
    "        if len(sources) < 5:\n",
    "            sources += get_for_priority('top', top=False)\n",
    "        \n",
    "        if len(sources) < 5:\n",
    "            sources += get_for_priority('medium', top=False)\n",
    "        \n",
    "        return sources\n",
    "    \n",
    "    def sample_articles(self, country='gb', language='en', year=2023, month=6,\n",
    "        query='Food', domain=None):\n",
    "        from_date = datetime.date(year, month, 1)\n",
    "        to_date_exclusive = from_date + dateutil.relativedelta.relativedelta(months=1)\n",
    "        to_date = to_date_exclusive + dateutil.relativedelta.relativedelta(days=-1)\n",
    "        query_translated = self.translate(query, to=language, cache=True)\n",
    "\n",
    "        params = {\n",
    "            'country': country,\n",
    "            'language': language,\n",
    "            'from_date': from_date,\n",
    "            'to_date': to_date,\n",
    "            'q': query_translated.get_translated(),\n",
    "            'apikey': newsdata_key\n",
    "        }\n",
    "        \n",
    "        if domain:\n",
    "            params['domainurl'] = domain\n",
    "        \n",
    "        response = requests.get(\n",
    "            self._news_data_endpoint + 'archive',\n",
    "            params=params\n",
    "        )\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            raise RuntimeError('Error (%d): %s' % (response.status_code, response.text))\n",
    "\n",
    "        results_json = response.json()\n",
    "        results = results_json['results']\n",
    "\n",
    "        locale = Locale(country, language)\n",
    "\n",
    "        def parse_result(record):\n",
    "            url = record['link']\n",
    "            keywords = record['keywords']\n",
    "            creator = record['creator']\n",
    "            publish_datetime = record['pubDate']\n",
    "            category = record['category']\n",
    "\n",
    "            title_untranslated = record['title']\n",
    "\n",
    "            content_pieces = [\n",
    "                record['content'],\n",
    "                record['description']\n",
    "            ]\n",
    "            content_pieces_valid = filter(\n",
    "                lambda x: x != None,\n",
    "                content_pieces\n",
    "            )\n",
    "            content_untranslated = ' '.join(content_pieces_valid)\n",
    "\n",
    "            title = self.translate(title_untranslated, source=language)\n",
    "            content = self.translate(content_untranslated, source=language)\n",
    "\n",
    "            return Article(\n",
    "                url,\n",
    "                title,\n",
    "                keywords,\n",
    "                creator,\n",
    "                content,\n",
    "                publish_datetime,\n",
    "                category,\n",
    "                locale\n",
    "            )\n",
    "\n",
    "        parsed_results = map(parse_result, results)\n",
    "        return parsed_results\n",
    "    \n",
    "    def translate(self, target, source='en', to='en', cache=False):\n",
    "        if source == to:\n",
    "            return TranslatedText(target, source, target, to)\n",
    "\n",
    "        if not cache:\n",
    "            return self._translate_force(target, source=source, to=to)\n",
    "        \n",
    "        assert 'en' in [source, to]\n",
    "\n",
    "        if target not in self._translate_cache:\n",
    "            self._translate_cache[target] = {}\n",
    "\n",
    "        if to not in self._translate_cache[target]:\n",
    "            translated = self._translate_force(target, source=source, to=to)\n",
    "            self._translate_cache[target][to] = translated\n",
    "\n",
    "        return self._translate_cache[target][to]\n",
    "    \n",
    "    def _build_translate_client(self):\n",
    "        return boto3.client(\n",
    "            service_name='translate',\n",
    "            region_name=self._aws_region,\n",
    "            use_ssl=True,\n",
    "            aws_access_key_id=self._aws_key['access'],\n",
    "            aws_secret_access_key=self._aws_key['secret']\n",
    "        )\n",
    "    \n",
    "    def _translate_force(self, target, source='en', to='en'):\n",
    "        chunker = TranslateChunker()\n",
    "        \n",
    "        for char in target:\n",
    "            chunker.process(char)\n",
    "        \n",
    "        chunker.finish()\n",
    "        \n",
    "        pieces = list(chunker.get_chunks())\n",
    "        \n",
    "        def translate_piece(piece):\n",
    "            response = self._translate_client.translate_text(\n",
    "                Text=piece, \n",
    "                SourceLanguageCode=source,\n",
    "                TargetLanguageCode=to,\n",
    "            )\n",
    "            return response\n",
    "        \n",
    "        pieces_responses = map(translate_piece, pieces)\n",
    "        pieces_translated = map(lambda x: x['TranslatedText'], pieces_responses)\n",
    "        translated = ' '.join(pieces_translated)\n",
    "        \n",
    "        return TranslatedText(\n",
    "            target,\n",
    "            source,\n",
    "            translated,\n",
    "            to\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newsdata_key.txt') as f:\n",
    "    newsdata_key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aws_key.json') as f:\n",
    "    aws_key = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facade = QueryFacade(newsdata_key, aws_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'I want to do some research.'\n",
    "facade.translate(target, to='es').get_translated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Food'\n",
    "facade._translate_force(target, to='es').get_translated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = facade.sample_sources('bd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_bd.json', 'w') as f:\n",
    "    response_json = [x.to_dict() for x in response]\n",
    "    json.dump({'entries': response_json}, f, indent=2)\n",
    "    print('Wrote %d sources.' % len(response_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = facade.sample_sources('us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_us.json', 'w') as f:\n",
    "    response_json = [x.to_dict() for x in response]\n",
    "    json.dump({'entries': response_json}, f, indent=2)\n",
    "    print('Wrote %d sources.' % len(response_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = facade.sample_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_en.json', 'w') as f:\n",
    "    response_json = [x.to_dict() for x in response]\n",
    "    json.dump({'entries': response_json}, f, indent=2)\n",
    "    print('Wrote %d articles.' % len(response_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = facade.sample_articles(country='mx', language='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample_es.json', 'w') as f:\n",
    "    response_json = [x.to_dict() for x in response]\n",
    "    json.dump({'entries': response_json}, f, indent=2)\n",
    "    print('Wrote %d articles.' % len(response_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
